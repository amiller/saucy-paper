\todo{I realized that I should introduce the concept of environment forcing progress before all the details here}

One of the main hurdles to existing UC models is that asynchronous/synchronous communication models uncecessarily complicate the design of protocols and ideal functionalities.
Not only does it make writing and switching between models cumbersome and error-prone, but it also mmake security proofs difficult to understand and even harder to verify.
Our construction removes all model-specific code from protocols and ideal functionalities, defines code that each ITI must be spawned with, and uses the new import mechanism to provide communiation guarantees.
%One of the key driving forces behind this work is an implementation of UC that simplifies working withe UC through simpler communication models and a domain-specific language. (\todo{$\leftarrow$ this is a real hot pile})

In this section we define our synchronous and asynchronous communication models which enable delaying execution of entire code blocks and offload all communication specific code from the protocols and functionalities to our new shared functionality. 
We construct our models using the GUC-framework~\ref{guc}---enabling the environment to force progress in protocols \todo{$\leftarrow$ probablt nt worth bringing up the environment part here}.

At a high level, the goal of the wrapper is to enable ITIs to schedule code blocks for future execution.
An ITI that wants to execute some code with adversarial delay informs the wrapper of the code and to asks it for activation when it's time to execute.
The adversary can control when the codeblock is executed, of course, by spending import tokens to delay its exeution or force execution at any time, but the environment can also force a code block to execute.
This ensures that an adversary can not stall protocol progress indefinitely.
Therefore, the main idea in our construction is that, although the adverasry can control delay and add more delay, it's import token balance (always less than the environment's) can never delay indefinitely, and the environment can ensure that no code blocks are delayed indefiniely.

%Before we divulge the details of how our model is implemented, we first give an example illustrating the disadvantage of current asynchronous (w.l.o.g synchronous) models compared to ours.
Before diving into the details of how the wrappers are implementated, and their consequences, we first give an example illustrating the simplicity of our model compared to traditional UC communication.
Take, for exampe, a simple atomic broadcast functionality in Figures \ref{fig:atomic:old} and \ref{fig:atomic:new}. 
The top figure is the atomic broadcast written in the traditional fetch-based asynchronous model.
Parties submit messages to be broadcast and must continually be activated by the environment to check for check for new results and ultimately move the functionality forward.
The adversary, meanwhile, can add delay and force more calls to \textsc{Fetch} be made.
Our version on the other hand, Figure \ref{fig:atomic:new}, simplifies the pseudo-code by offloading model-specific behavior to the wrapper.
It makes use of the keyword \Eventually, which is used only for clarity in pseudo-code but is useful abstraction in our implementation.
Despite the abstraction, however, \Eventually only substitutes a single message write from the point of view of the functionality.
The exact pseudo-code is shown in the final figure, Figure~\ref{fig:atomic:real}.

\begin{figure}[h]
\begin{subfigure}{\columnwidth}
	\input{figures/fatomic_old}
	\caption{An atomic broadcast functionality in the fetch model for the asynchronous world.}
	\label{fig:atomic:old}
\end{subfigure}
\begin{subfigure}{\columnwidth}
	\input{figures/fatomic_new}
	\caption{The same atomic broadcast functionality written with our async wrapper construction. Notice that there is no extra pseudo code needed to operate in this model.}
\end{subfigure}
\begin{subfigure}{\columnwidth}
	\input{figures/fatomic_real}
	\label{fig:atomic:real}
\end{subfigure}
\end{figure}

\todo{I absolutely hate having introduced the above {\em first} now}

\subsection{Asynchronous Wrapper}
In Figure~\ref{fig:async:wrapper}, the async wrapper, \Wasync, accepts code blocks in the form of a \msf{schedule} message, or, alternatively, when code uses the \textsc{Evetually} keyword.
A \msf{schedule} message is accompanied by an identifier that the wrapper will send back to the caller when it's time to execute the codeblock.
The identifier is sent back to the calling party when the code is ready to be executed. 
In our running atomic broadcast example, \Wasync sends a \textsc{Broadcast} back to the caller along with the message to be broadcast.

Once scheduled, the codeblock is added to the \msf{runqueue} until it is executed by the wrapper (we will elaborate on the conditions for execution later).
When it's time to execute (triggered either by the adversary or the environment), \Wasync writes an \Exec message back to $\F_{\msf{atomic}}$ instructing it to execute the \textsc{Broadcast} which then schedules sending the message to the different parties. 

The \Exec interface that $\F_{\msf{atomic}}$ accepts is not illustrated in Figure~\ref{fig:atomic_real}, however it is an interface that all ITIs that wish to schedule codeblocks must implement.
It is the only message that a scheduling ITI expects to receive from \Wasync and is a relatively lightweight addition. 

\subsection{Executing Codeblocks}
Codeblocks can be executed in two ways in both the synchronous and asynchronous wrappers: by the adversary and by the environment \footnote{Recall that the environment can force the wrappers to make progress by sending {\em enough} \Advance messages to it.}.
The adversary, of course, has control over the delay before a code block execute but is limited by the available import which prevents it from halting protocol progress.
To this effect the adversary can also execute a code block at a certain index at any point in execution through the \Exec interface.

The environment can can also execute code blocks by exhausting the import available to the adversary and forcing progress to be made in \Wasync.
We detail the {\em eventual delivery} property in a later section, however, at a high level: the environment has a greater balance of import than the adversary so it can always send an \Advance message (1 unit of import) to \Wasync more than the adversary can \Delay (1 unit of import).
The cost of each of the operations is detailed in Figure \ref{fig:asyncwrapper:short}.


\subsection{Import}
In the previous subsection we state that the environment can force progress to be made in the wrapper by exhausting the amount of import that the adversary can use to delay.
However, from our previous discussion regarding \textit{balanced environments} in Section~\ref{sec:import} we arrive at a problem: \textit{for every unit of import that \Environment sends to an ITI, it must also send to \Adversary}.
This would suggest that the adversary will \textit{always} have enough import to prevent the environment from advancing the wrapper, and, therefore \Adversary can delay codeblocks indefinitely.
We address this problem by relaxing the balanced environments constraint in the GUC framework for shared functionalities.

We motivate our relaxing of the balanced environments constraint, first, by addressing ~\ref{prop:balancedenvironments}. 
In summary, the the argument states that when a protocol is extended trivially to instruct $\pi_i$ to send a message to \Adversary proportional to it's import, the environment can ensure the $\pi_i$ always has more import than the \Adversary and, therefore, the adversary is no longer simulatable. 
We can conclude that the constraint exists to make the framework more expressive rather than as a technical requirement to achieve simulation or composition. 
Therefore we relax the balanced environments constraint for our shared functionality in the following way and for the following reasons:
\begin{itemize}
\item We remove the requirement for \Environment to give import to \Adversary corresponding to the import spend calling \Advance in the wrapper.  
\end{itemize}

\todo{below this line is no longer up to date}
The full wrapper can be seen in Figure~\ref{fig:wrapper:async}.

The wrapper maintains accepts message through the \msf{schedule} interface which specifies the code block to be executed.
The \Eventually keyword mentioned above is a stand in for this message write from an ITI to the wrapper.
Upon \msf{schedule}, the wrapper records the codeblock in the \msf{runqueue} and increments a delay variable.
The delay v


\subsection{Balanced Environments}
Some rough ideas on the writeup for this section.
In the GUC setting the environment’s interaction with the shared functionality is intended to represent parties from other sessions of potentially different protocols. 
Therefore, intuitively, it doesn’t make sense that participants of the challenge protocol have a different interface to those of other sessions. 
Therefore, in order to fit within the GUC framework, we require that protocol parties also be able to call “poll” to the wrapper. 
Although this seems counter intuitive, it has no impact on the delivery properties or functionality of the wrapper. 
The reason is the balanced environments definition presented above. 
As expected in UC, an environment that gives import to parties in order to call “poll” must give that import to the adversary as well. 
Therefore, the adversary will always have enough import to effectively neutralize any calls to “poll” that parties of the challenge protocol make. 
As the wrapper is a shared functionality, a simulator need only observe which protocol session’s party calls “poll” and add “delay” to the wrapper if it’s the challenge protocol session.  

Specific to this wrapper construction is the idea that the environment doesn’t have to give the simulator the same construction as the ideal wrapper in this case. 
This leads to a place where we explicitly reject the balanced environment condition for our wrapper construction as it further relaxes the constraints on the environment without sacrificing simulatability. 
We show that the simulator always has enough import to at least delay codeblocks in the ideal world enough such that they can be delivered at the same time. 
Therefore, the simulatability requirements are already satisfied by the wrapper delay incrementing on every scheduled code block and, hence, the simulator receiving as much import as the real world parties can always delay.

It’s not enough that constant sized output shared functionalities be exempt from the balanced environment definition. Because you can still have a shared functionality that requires the adversary to react a \# of times proportional to the import of the shared functionality and then the adversary runs out of import because the environment can always give more import to the shared functionality than it does the adversary.
In the case of the wrapper, however, we specifically require that the adversary run out of import eventually but not so quickly that it is unable to delay the codeblocks in the ideal world.



Distinction in features and side effects
\begin{itemize}
\item Features: explicit design goals that the wrapper achieves. This includes:
	\begin{itemize}
	\item Simplifying through the removal of model-specific code in the pseudo-code. Improves using UC from people verifying proofs and creating there own. Towards the programmability we're aiming for?? but what exactly is the programmability message here
	\item Uses import to achieve eventual delivery in asynchronous networks and input completeness in synchronous network.
	\item Offloading work from protocols/functionalities to the wrapper and some work to the environment but without useless fetches.
	\end{itemize}

\item side effects:
	\begin{itemize}
	\item doesn't lose activation
	\item all functionalities and must give control back to caller. p2p messages go through a functionality and must be delayed in the wrapper so functionalities can only write to other functionalities after being activated. Recursively, at some ponint either a code block is schedules or some local computation is completed and the functionality halts. In both cases, wrie back to caller instead --> makes riting code better. Not necessary but reomves conditions from environment.
	\end{itemize}
\end{itemize}



The asynchronous wrapper, presented in Figure~\ref{fig:asyncwrapper:short}, is only a snippet of the important parts of the full wrapper code shown in ~\ref{fig:asyncwrapper:complete}.
We first cover the basic operations of the wrapper.


\subsection{Delayed Code Execution}
In traditional synchronous and asynchronous communication models, adversrial delay usually takes the form of only message delay where parties require continuous activation in order to request new messgaes from a message passing functionality or cedeing control to the adversary mid-activation.
An example of whot this can lead to more complicated environents and protocols is evident in the synchronous model of Katz et al.~\cite{katzclock}. 
Even the original formulation of aysnchronous communication had issues where adversaries were able to indefinitely stall protocol progress.

Our construction, on the other hand, offloads much of the communication model-specific code, to our shared wrapper.
Further, it expands message delay to the delay of entire code blocks, and it also also simplifies
example of this in figure~\ref{fig:rbc:both}.


\paragraph{\textsc{Eventually} Keyword.}
For the remainder of this work, we will make advantages of keywords that abstract the message passing between the sync/async wrappers and other ITIs.
The most important codeword is the \textsc{Eventually} keyword which is used to indicate delayed execution of a code block within the code of some ITI.
For example, the simple message passing functionality introduced in Figure~\ref{fig:fsmcasync}, is transformed into Figure~\ref{fig:fsmc:wrapper}.

\begin{figure}
\input{figures/asyncwrapper_short}
\caption{The wrapper mechanism for scheduling codeblocks and executing them.}
\label{fig:asyncwrapper:short}
\end{figure}
